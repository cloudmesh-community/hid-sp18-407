Notes: 
- Page limit 8 pages. Should be about why this tech is important, why it's exciting, what does it do? 
- Tutorial - tell about technology and build tutorial.  Precursor to project. 
- Project = how do you actually run project so a TA can actually replicate. Shouldn't have 50 steps.  Need to include a makefile or show video of how something is run.  Containerize! 
- Makefile is super important. Learn how to create/run a makefile! 
- don't check in any code that we haven't developed.  e.g. swagger codegen.  
- we can ship code that doesn't require all the code.  
- Swagger service - we will use the swagger service in the project. 
- Apache Kudu/Impala
	- Note the different tones between academic papers and documentation.  



Title: Processing Massive Datasets at Scale with Open Source Software: Apache Kudu and Cloudera Impala. 

/Section - Why is Apache Kudu significant? 
SQL was the dominiant language for working with data until the 2000's.  With the explosion in the volume and velocity of data, programmers struggled to scale SQL-based storage and query engines to meet demand; thus NoSQL was born. Relational Database Management Systems (RDBMS) platforms are being designed once again as processing power overcomes the hurdles for which NoSQL was originally designed. Many of the reasons that contributed to the decline of RDBMS became unpopular are no longer relevant, or the problems have been solved. Developers can now choose a programming paradigm depending on their specific needs without sacrificing performance or usability, and without having to create complex architectures.

<<<<<<< HEAD
In 2015, Cloudera donated both Impala and Kudu projects to the Apache Software Foundation in hopes that a full-time developer community would spark the projects into stable, widely adopted platforms. 
=======
In 2015, Cloudera donated both Impala and Kudu projects to the Apache Software Foundation
>>>>>>> 116b23d90dabd990f1a15372e5f84729e44b8500

/Section - Intro

Kudu and Impala together provide many advantages.  With Kudu, a user can access many data stores through a single query engine like Impala. With Impala, many sources of data can be queried from a single SQL interface, such as Hive, Hbase, or naturally Kudu. Kudu is tightly integrated with Impala, but supports the entire Apache ecosystem including Spark, Hive, Hbase, and others. Cite 14. Because both platforms are part of the Hadoop ecosystem, their capabilities are greatly expanded through interoperability with the data stores, cluster managers, and visualization tools. 

Kudu was started in 2014 and is now a Top-Level Project within Apache. Driven by need to ingest, update, and analyze massive datasets at scale, given a low-cost, open-source framework, Kudu is described as an open-source storage engine for structured data designed to provide low-latency random access to distributed data souces, particularly within the Hadoop ecosystem.  "At a high level, Kudu is a new storage manager that enables durable single-record inserts, updates, and deletes, as well as fast and efficient columnar scans due to its in-memory row format and on-disk columnar format."  Cite 14. One of the main advantages Kudu offers is a simple API for row-level writes, updates, upserts, and deletes, while maintaining query throughput speeds similar to binary stores such as Apache Avro. Cite 17. Impala is a SQL engine providing low-latency, high-concurrency access for business intelligence-type analytic queries on HDFS.  Cite 13. 


/Section - Kudu

Kudu benefits from several design choices aimed at bridging the gap between static and dynamic data stores. Static Hadoop data stores such as Apache Avro or Parquet have limited ability to write but low-latency interactivity. These "traditional" data management stores in represent immutable databases and are more suited to unstructured or semi-structured streaming data. Cite 1. Whereas semi or unstructured stores such as Hive can read and write real-time data but provide less-than-optimal analytical performance. Cite 2. Mutable databases like Hbase allow for low-latency record-level reads and writes, but lag behind the static file formats for sequential read-through for applications like SQL-based analytics and machine learning.  Cite 14. 
<<<<<<< HEAD

"Kudu fills the gap between immutability in static data stores and latency during sequential read-through in mutable databases, and offers several improvements and design choices in read, write, distribution, and maintenance operations."  Cite 1. **INCLUDE PICTURE HERE**

//caption: 


**MOVE TO SEGUE WITH IMPALA?**
This architecture makes Kudu very attractive for storing streaming data that may need to be modified at a later time, such as healthcare or weather data. Cite 7. "Today, many users try to solve this challenge via a Lambda architecture, which presents inherent challenges by requiring different code bases and storage for the necessary batch and real-time components." Cite 14. Kudu and Impala together circumvents the need for such complex architecures, as they are well-suited for real-time interactivity and are designed to be tightly integrated.  

/Section - How does Kudu do this?

Kudu utilizes a flexible array of horizontal partitioning schemes to achieve high-throughput storage and low-latency random access. Contrast other distributed data stores such as Hbase or Cassandra which use either key-range horizontal partitioning, or hash partition methods respectively. In Kudu, "the partition schema acts as a function which can map from a primary key tuple into a binary partition key.  Each tablet covers a contiguous  range  of  these partition  keys.   Thus,  a  client,  when performing a read or write, can easily determine which tablet should hold the given key and route the request accordingly."  

=======

"Kudu fills the gap between immutability in static data stores and latency during sequential read-through in mutable databases, and offers several improvements and design choices in read, write, distribution, and maintenance operations."  Cite 1. **INCLUDE PICTURE HERE**

**MOVE TO SEGUE WITH IMPALA?**
This architecture makes Kudu very attractive for streaming data that may need to be modified at a later time, such as healthcare or weather data. Cite 7. "Today, many users try to solve this challenge via a Lambda architecture, which presents inherent challenges by requiring different code bases and storage for the necessary batch and real-time components." Cite 14. Kudu and Impala together circumvents the need for such complex architecures, as they are well-suited for real-time interactivity and are designed to be tightly integrated.  

/Section - How does Kudu do this?

Kudu utilizes a flexible array of horizontal partitioning schemes to achieve high-throughput storage and low-latency random access. Contrast other distributed data stores such as Hbase or Cassandra which use either key-range horizontal partitioning, or hash partition methods respectively. In Kudu, "the partition schema acts as a function which can map from a primary key tuple into a binary partition key.  Each tablet covers a contiguous  range  of  these partition  keys.   Thus,  a  client,  when performing a read or write, can easily determine which tablet should hold the given key and route the request accordingly."  

>>>>>>> 116b23d90dabd990f1a15372e5f84729e44b8500
/Section: Fault-tolerant distributed Data

Kudu uses the Raft consensus and horizontal partitioning of tables into tablets. Different from Parquet, which uses vertical partitioning, providing performance advantages in partial queries and retrievals. 
 
Raft implements consensus by first electing a distinguished leader, then giving the leader complete responsibility for managing the replicated log. The leader accepts log entries from clients, replicates them on other servers, and tells servers when it is safe to apply log entries to their state machines. Having a leader simplifies the management of the replicated log. For example, the leader can
decide where to place new entries in the log without consulting other servers, and data flows in a simple fashion from the leader to other servers. A leader can fail or become disconnected from the other servers, in which case a new leader is elected.  - page 3 in raft paper. Note, the concept of a leader/follower is different than a master/client relationship. 
<<<<<<< HEAD

Kudu stores most of its data in a familiar-to-RDBMS columnar format.  Each column is stored, encoded, and compressed separately in small partitions.  Indices allow fast seeking by key or position and delta stores allow tracking of updated and deleted rows.  Cite 1.  

Because Kudu stores data in columnar format, it is not suited for unstructured data. 

**MIGHT BE OUT OF SCOPE OF THE PAPER**
Kudu storage on Disk: 
"Caches all metadata for Replicated Tables in RAM for optimal performance." 
**MemRowSet and DiskRowSet - MemRowSet is in-memory storage that frequently gets "rolled" to DiskRowSet. A detailed explanation of these processes is beyond the scope of this paper, but can be found **here** {the Kudu paper}. 

=======

Kudu stores most of its data in a familiar-to-RDBMS columnar format.  Each column is stored, encoded, and compressed separately in small partitions.  Indices allow fast seeking by key or position and delta stores allow tracking of updated and deleted rows.  Cite 1.  

Because Kudu stores data in columnar format, it is not suited for unstructured data. 

**MIGHT BE OUT OF SCOPE OF THE PAPER**
Kudu storage on Disk: 
"Caches all metadata for Replicated Tables in RAM for optimal performance." 
**MemRowSet and DiskRowSet - MemRowSet is in-memory storage that frequently gets "rolled" to DiskRowSet. A detailed explanation of these processes is beyond the scope of this paper, but can be found **here** {the Kudu paper}. 

>>>>>>> 116b23d90dabd990f1a15372e5f84729e44b8500
Kudu Integrations. 
Kudu is written with APIs in Java, C++, and Python, and is designed on top of the Hadoop ecosystem. Accordingly, Kudu integrates with several key Hadoop components including MapReduce, Spark, and of course, Impala. 

* Definitions
- Horizontal Partitioning. 
- Tablets.  Horizontally partitioned tables.
- MemRowSet
- DiskRowSet
- 

* Advantages/Drawbacks of Kudu over NoSQL databases (use graph image here). 
	-- Kudu vs. other softwares: 
	-- Spanner. Direct competitor to Spanner. 
	-- Hive performs well with 

* Advantages/Drawbacks of Impala: 

Raft Consensus Method:


Kudu improves upon the Raft algorithm in two ways: First, by using an exponential back-off algorithm to avoid data packet collisions after a failed leader election. Essentially, the backoff algorithm works by randomly choosing increasing time delay values for clients to send data until there is no longer a conflict.  

Second, when a new leader contacts a client whose log diverges from its own, Raft proposes iteratively stepping backward until the point where the two logs diverge. Kudu proposes immediately jumping back to the last committedIndex, potentially saving many steps.  

Fractured Mirrors, or "Decomposition Storage Model vertically partitions all attributes of a given relation"
Example Applications in Depth. Abstract at https://dl.acm.org/citation.cfm?id=1287407

Understanding Partitioning in Kudu is Necessary to Optimize Performance

The Kudu paper - page 4. 
Replication in Kudu. Kudu replicates its table data across multiple machines. The user selects a replication factor (usually 3 or 5), and the Kudu master attempts to maintain the given number of replicas. (The Kudu paper, 3.4.2). 

Tablet Storage Goals: 
1. Fast Columnar scans
2. Low-latency random updates
3. Consistency of performance. 

MemRowSet and DiskRowSet implementation. Design broadly based on MassTree **cite**

MVCC = multi-version concurrency control.

* Writability. 
INSERT and ALTER TABLE operations are the primary advantage Kudu has over non-relational, or NoSQL databases like Hbase or Cassandra. The immutability of NoSQL databases provides significant performance advatages over traditional RDBMS, but at the expense of write capabilities. The converse is true for traditional relational databases.  Kudu fills this gap, offering lower latency benchmarked performance over relational databases such as MySQL, and writability-upon-ingestion not found in NoSQL databases. 

"If a client wishes to write, it first locates the leader replica and sends a write request to that replica. If that replica is no longer the leader, the request will error out, the replica will refresh its metadata cache, and a new request will be resent to the new leader."  While this process may seem cumbersome or error prone, Kudu's robust scheduling manager is designed with fault-tolerance and performance in mind. Obviously recording the correct order of the entries is paramount, which Kudu accomplishes with a local lock manager.  "If a majority of the followers accept the write and log it to their own local write-ahead logs, the write it considered durably replicated"
**the kudu paper page 4**

* Decoupling of storage and distribution increases Kudu's performance by avoiding the 
New hybrid columnar storage architecture. 

** Summary regarding tablet storage: 
"
** Schema Design: 
Apache Kudu Schema Design. **Cite 7**
Kudu takes advantage of strongly-typed columns. As such, users should specify column type vs. using a schema-less table as in a NoSQL database.  This provides the advantage of Kudu feeling and acting in many ways like a familiar Relational Database, while allowing for improved read-write performance over NoSQL databases. 

** Column encoding: 
Columns can be encoded depending on the type in one of five ways: plain, bitshuffle, run length, prefix, and dictionary. Plain encoding is data stored in its natural format, whereas bitshuffle 

"Arranging a typed data array in to a matrix with the elements as the rows and the bits within the elements as the columns, Bitshuffle "transposes" the matrix, such that all the least-significant-bits are in a row, etc. This transposition is performed within blocks of data roughly 8kB long; this does not in itself compress data, but rearranges it for more efficient compression. A compression library is necessary to perform the actual compression." http://adsabs.harvard.edu/abs/2017ascl.soft12004M

*Security: 
Security and encryption are two concerns and something that Kudu team treats seriously. Kudu uses Hadoop security roles and permissions via Kerberos authentication. 

As of the date of this writing.  Kudu also integrates with Apache Sentry, which provides role-based authentication methods.  "System-wide security is supported for Kudu API calls, but one can still use Apache Sentry with Impala to secure Kudu tables for the end users."  Kudu has been tested to support common encryption software, but this area may leave somewhat of a gap.  
**http://boristyukin.com/benchmarking-apache-kudu-vs-apache-impala/**

 

Impala:
* Impala primer {the Impala paper} Modern, Open-Source SQL engine for Hadoop environments. Low-latency, high concurrency for BI/analytic queries on HDFS.  

* Primary Features: Cite 13
** Impala provides familiar SQL-style query commands, including SELECT, INSERT, CREATE TABLE, ALTER TABLE, joins, and aggregate functions. 

(Enumerate)
** HDFS and Hbase storage and codecs, including HDFS file formats Avro, Kudu, and Parquet and compression codes Snappy and GZIP among others.  

** JDBC and ODBC interfaces

** Command-line interface

** Kerberos authentication. 

* Benefits include no batch framework - Impala supports real-time, streaming analytics.  Impala shows that it is possible to build a low-latency interactive analytics platform on a batch-processing data framework. 

* History. 

* Performance Comparisons
**Hive: Impala circumvents MapReduce and uses a distributed query engine to outperform Hive significantly.  

* Architecture: 
Impala is a MPP, or Massively Parallel Processing platform, capable of running on very medium to large Hadoop clusters with minimal additional setup.  An Impala instance is comprised of three services: an Impala daemon, a Statestore daemon, and a Catalog daemon.  Similar in concept to Kudu's leader-client model, the Impala daemon functions both as a query receiver from Impala's back-end, and as a coordinator or leader for a particular query. The Statestore and Catalog daemons handle metadata operations.  All three services are coordinated by Cloudera Manager, which is designed to manage an entire Hadoop deployment.  

Take-away, challenges. 

* The focus here is on speed as the only metric.  The authors of Impala are able to demonstrate that the platform consistently outperforms proprietary databases, sometimes be a factor of 4.5x.  What is not measured is opportunity or switching cost. Many enterprises will not be ready to turn away from their current legacy systems, even when faced with the promise of significant performance increases.  

Example Use Cases

Future of Kudu 
1) Offering different options for storage layouts. 

Cite 1: "the Kudu paper"
https://kudu.apache.org/kudu.pdf

Cite 2: "the Impala paper"
http://cidrdb.org/cidr2015/Papers/CIDR15_Paper28.pdf

Cite 3: "Raft consensus algo"
https://raft.github.io/raft.pdf

Cite 4: Decomposition Storage Model
https://dl.acm.org/citation.cfm?id=1287407

Cite 5: Benchmarking Impala on Kudu vs. Parquet
**http://boristyukin.com/benchmarking-apache-kudu-vs-apache-impala/**

Cite 6: 
Performance comparison of different file formats and storage engines in the Apache Hadoop ecosystem: 
https://blog.cloudera.com/blog/2017/02/performance-comparing-of-different-file-formats-and-storage-engines-in-hadoop-file-system/

Cite 7: 
Kudu Schema Design
https://kudu.apache.org/docs/schema_design.html

Cite 8: 
Encoding type definitions: 
https://github.com/apache/parquet-format/blob/master/Encodings.md

Cite 9: 
Kudu and Impala - Kudu vs. Spanner
https://kudu.apache.org/2017/10/23/nosql-kudu-spanner-slides.html

Cite 10: Bitshuffle
http://adsabs.harvard.edu/abs/2017ascl.soft12004M

Cite 11: Consistency in Apache Kudu
https://kudu.apache.org/2017/09/18/kudu-consistency-pt1.html

Cite 12: A brave new world in mutable big data: Relational Storage
https://kudu.apache.org/2017/10/23/nosql-kudu-spanner-slides.html

Cite 13: Impala features: 
https://www.cloudera.com/documentation/enterprise/5-3-x/topics/impala_intro.html

Cite 14:  Kudu and Impala Primer: 
https://blog.cloudera.com/blog/2016/09/apache-kudu-and-apache-impala-incubating-the-integration-roadmap/

Cite 15: 
http://www.clouderaworldtokyo.com/session-download/B3-Kudu-2FImpala-Strata-talk.pdf

Cite 16: Cloudera donates both Kudu and Impala to ASF:
https://adtmag.com/articles/2015/11/18/cloudera-donates-projects.aspx

Cite 17: Kudu Proposal 
https://wiki.apache.org/incubator/KuduProposal

Cite 18: Impala Proposal
https://wiki.apache.org/incubator/ImpalaProposal








