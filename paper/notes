Notes: 
- Page limit 8 pages. Should be about why this tech is important, why it's exciting, what does it do? 
- Spark is ok.  516 is Hadoop related. 
- Tutorial - tell about technology and build tutorial.  Precursor to project. 
- Project = how do you actually run project so a TA can actually replicate. Shouldn't have 50 steps - how does a makefile work? 
- Makefile is super important. Learn how to create/run a makefile! 
  - don't check in any code that we haven't developed.  e.g. swagger codegen.  
  - we can ship code that doesn't require all the code.  
- Hadoop...look at chameleon cloud's hadoop deployment.  
- Containers. 
- Swagger service - we will use the swagger service in the project. 


Paper Topic: 
Vagrant.  
Vagrant is a command-line utility for managing virtual environments. Developed in 2009 by Mitchell Hashimoto and John Bender, Vagrant was originally designed to replace the 2010-era web development practices associated with largely static web environments.  With the advent of dynamic languages such as Python, Ruby, and other extensible frameworks, the need arose for portable and disposable development environments that could be rapidly created and just as quickly destroyed.  

Mitchell Hashimoto and John Bender formed Hashicorp in 2010 to work on Vagrant full-time after starting the software as a side project in the late 2000's. Other projects include Vault, Serf, Packer, and **insert company information here**.  

Vagrant builds on virtualized environments like VirtualBox and VMware. 

Built to combat "Works on my machine" . 

"Vagrant puts your development environment into a virtual machine".  Oreilly/Hashimoto

John Bender. 

License?  

Commands https://www.linuxjournal.com/content/introducing-vagrant: 

init — create the base configuration file.
    up — start a new instance of the virtual machine.
    suspend — suspend the running guest.
    halt — stop the running guest, similar to hitting the power button on a real machine.
    resume — restart the suspended guest.
    reload — reboot the guest.
    status — determine the status of vagrant for the current vagrantfile.
    provision — run the provisioning commands.
    destroy — remove the current instance of the guest, delete the virtual disk and associated files.
    box — the set of commands used to add, list, remove or repackage box files.
    package — used for the creation of new box files.
    ssh — ssh to a running guest. 

Paper citations: 
Vagrant documentation: Official site: https://www.vagrantup.com/docs/index.html

Linux Journal: https://www.linuxjournal.com/content/introducing-vagrant:  (Introducing Vagrant, history)

Vagrant: Up and Running, o'reilly media. Mitchell Hashimoto

# Core concepts: 
## Virtualization
Virtual environments are disposable. 
"guests can be base for a project without contamination" **what does this mean exactly?  Translate this concept into practical. 

## Vagrant File: 
Vagrantfiles are like makefiles, written in Ruby syntax. 

##Boxes.  What are Vagrant boxes?  Base computer images.  
List of vagrant boxes. 












____________________________________________________

Project ideas: 
What about a service that sends and retrieves data using spark streaming. 
What if you typed in twitter, it might give you the most current 50 tweets. 
If you type in "news" it might give you the most current 50 news stories.  
The Service is going to store these in a mongodb?  


RDD - what is an RDD?  RDD stands for resilient distributed database, which is the Spark abstraction for data storage.  


Spark Session
As compared to Spark SQL

Spark SQL
Spark SQL is the entry point for working with structured data in dataframes:  
- http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.SQLContext
- Spark SQL has a nice JDBC interface for reading JSON and Hive files. 

Spark Streaming
This is Spark's module for big data functionality.  It interacts with other Spark modules such as MLib. 

MLib
Spark's machine learning library. 
https://spark.apache.org/docs/1.2.2/ml-guide.html

schema rdd
https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.sql.SchemaRDD

Interactivity. 
Spark runs on the JVM and interacts with Python, Java, Scala and other high-level languages. 

